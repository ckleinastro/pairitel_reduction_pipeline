pairitel_reduction_pipeline
===========================

Codes to reduce PAIRITEL data.

The following is a write-up of the PAIRITEL Reduction Pipeline that appeared in Christopher Klein's PhD Dissertation (UC Berkeley, 2014).

Because {\it PAIRITEL} reused the {\it 2MASS} camera and unaltered readout electronics, each epoch consisted of multiple exposure triplets separated by $\sim$dozen seconds during which a small dither offset was enforced. Each single exposure in the triplet had an exposure time of 7.8 s. A single epoch generally consisted of 8 or 9 triplets, making for a total integration time of $\sim3$--$3.5$ minutes.

In support of this work on RR Lyrae period--magnitude relations, as well as the prime science goal of {\it PAIRITEL} to followup gamma-ray burst (GRB) afterglows, a new image reduction and co-addition pipeline was developed for the robotic telescope and deployed for near-real time operation. This software was the third and final reduction pipeline developed for {\it PAIRITEL}. It operated autonomously in concert with the telescope as new data was gathered each night, often providing reduced and coadded images within a few minutes of the end of an observation. This was particularly beneficial for quickly reacting to GRBs and issuing GCN circulars. The reduction pipeline also provided invaluable near-real time diagnostic information for the telescope supervisors when troubleshooting mechanical, technical, or telescope control system-related faults.

The {\it 2MASS} camera uses two dichroics and three near-infrared detectors to simultaneously record the $J$, $H$, and $K$ exposures. For the most part, the reduction pipeline operates on each waveband independently. However, because the images are taken simultaneously in each band, the relative and absolute astrometric solutions for the images need only be solved for $J$ and can then be applied to the two longer-wavelength (and less sensitive) $H$ and $K$ exposures.

The constrained image readout mode of {\it PAIRITEL} dictated much of how the reduction pipeline operated. Each ${7.8~{\rm s}}$ integration of a triplet exposure (called a ``long read'') was preceded by a ``short read'' of ${0.051~{\rm s}}$. The short read served as a bias read for the long read, and was subtracted from the long read as the first step in the reduction process. The short reads themselves were also processed to produce final coadded images with very short total exposure times. The advantage of processing the short reads is recovery of extremely bright sources that otherwise saturate in the long reads. This was the intended avenue for photometering the nearby bright RR Lyrae stars, such as RRLyr itself, but ultimately the photometric precision recoverable from the reduced and coadded short reads was found to be unacceptable.

In the near-infrared, the brightness of the atmosphere is significant and must be subtracted to improve the signal-to-noise ratio of astrophysical sources. The reduction pipeline creates median sky background images by masking pixels suspected to fall on sources and stacking temporally-adjacent images. The sky brightness fluctuates on 5- to 10-minute timescales, so for a given ``target'' exposure the pipeline uses the images recorded within $\pm5$ minutes to create this median sky flux image. (Of course, if the target exposure is within 5 minutes of the beginning or end of the observation period, then fewer adjacent images contribute to its sky flux image.)

It was found that the detector response varied significantly, and in a correlated manner, with the read-cycle position of the long reads in the triplet exposures. To account for this, a different sky flux image is produced for each of the three long reads in a triplet exposure, wherein only the first long read of each contributing triplet exposure is combined into the sky flux image corresponding to the first long read of the target triplet exposure, and so on for the second and third reads in the cycle.

The accuracy of this sky brightness subtraction procedure relies heavily upon correctly masking pixels containing flux from astrophysical sources from contributing to the median sky flux image. The reduction pipeline runs this sky subtraction procedure twice, first with a preliminary source pixel mask and then with a more refined, and conservative, source pixel mask constructed from the images resulting from summing long reads of each triplet exposure after subtracting the first iteration of the sky flux images. The source pixel masks were generated by employing a median absolute deviation outlier detection algorithm in combination with the objects check image output from SExtractor. The raw source pixel masks were then Gaussian smoothed (blurred) to expand the masked pixel area and account for diffuse emission from extended sources and the telescope's PSF. The dither steps between each triplet exposure were large enough to ``step over'' the footprints of unsaturated (and most saturated) point sources, as well as most galaxies with radii $\lesssim 30^{\prime\prime}$. 

After the sky flux subtraction, each triplet exposure is divided by archival flat frames for each detector (the autonomous software did not automatically acquire twilight flats during normal operations). Then each triplet exposure is directly pixel-wise summed to create a ``triplestack''. Each pixel is $2^{\prime\prime} \times 2^{\prime\prime}$, and the telescope jitter was far smaller, so this does not result in any significant smearing. The final step in the reduction process is to coadd the images and produce mosaics, but before this can be done the relative dither offsets must be measured from the pixel data and written into the FITS header WCS keywords. Note that an absolute astrometric solution is not necessary at this step, only a WCS solution that incorporates precisely correct relative offsets between the triplestacks. To accomplish this, the reduction pipeline runs SExtractor on each $J$-band triplestack and analyes the resultant catalogs to identify the deepest triplestack image. This deep triplestack, generally the image with the most well-detected sources, serves as the reference image from which the pixel offsets of the other images in the sequence are measured. The relative sky position offsets and rotations between the $J$, $H$, and $K$ detectors are well known and constant, so it is only necessary to measure the offsets in the $J$-band triplestack sequence.

A normalized cross-correlation image-alignment program (specially developed by E.~Rosten) is used to measure the pixel offsets between the reference triplestack and all other images in the sequence. In addition to the image pair, the alignment program also requires an approximate pixel offset (derived from the telescope control system's imprecise pointing data) and a search box width (default width is 9 pixels, but this can be adjusted as necessary for specific reduction requests). The computed pixel offsets are accurate at the sub-pixel level.

With relative pixel offsets in hand, the reduction pipeline writes appropriate WCS information into the FITS headers of the $J$, $H$, and $K$ triplestack sequences and then uses Swarp \citep{2002ASPC..281..228B} to median-combine and mosaic the reduced imaging data. Right before the final triplestack list is generated for Swarp, though, triplestack images with suspected bad WCS alignments or unreasonably few point sources are rejected (the most often cause of rejection at this point is variable poor sky conditions). In the mosaicing process the pixel resolution is changed from 2$^{\prime\prime}$ to 1$^{\prime\prime}$. Additionally, archival and dynamically-generated bad pixel masks are provided to Swarp for application in the coaddition process. The final astrometry is solved using astrometry.net \citep{lhm+10}, although sometimes the pipeline falls back on Scamp \citep{2006ASPC..351..112B} and then, if Scamp also fails, a specifically-developed pattern-matching Python program is employed.